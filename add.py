def image_error(d, message=None, errorNumber=None, url_images=None):
    with open(f'ERROR_{str(errorNumber)}.txt', 'w', encoding='utf-8') as f:
        f.write(pformat(d) + '\n')
        if message is not None:
            f.write(message + '\n')
        if url_images is not None and message == "æŒ‡å®šã—ãŸæ‹¡å¼µå­ä»¥å¤–ã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã™":
            for url in url_images:
                f.write(f'{url}\n')

    if message is not None:
        print(message)


def count_files_in_folder(folder_path):
    try:
        # ãƒ•ã‚©ãƒ«ãƒ€å†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆã‚’å–å¾—
        files = os.listdir(folder_path)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã®æ•°ã‚’è¿”ã™
        return len(files)
    except FileNotFoundError:
        print(f"æŒ‡å®šã•ã‚ŒãŸãƒ•ã‚©ãƒ«ãƒ€ '{folder_path}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        return None
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None
    
from bs4 import BeautifulSoup
import json
import os
import pandas as pd
import random
import requests
import time as ti
from pprint import pprint
from pprint import pformat

def load():
    error_title = ['ãã£ã‹ã‘ã¯ã©ã‚“ãªæ‰€ã«ã‚‚ã€‚2023å¹´ã‚‚ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸï¼ Part.1',
                   'ä»Šå¹´ã®æ¼¢å­—ä¸€æ–‡å­—ã¯ã€Œæ°·ã€',
                   'æƒ³ã„ãŒå±Šã„ãŸã‚‰ã„ã„ãªğŸ€',
                   'ãŸãã•ã‚“ã‚ã‚ŠãŒã¨ã†ã ã‚ˆã€œğŸ’—',
                   '0ã‹ã‚‰1ã«ã€‚',
                   'ğŸ€',
                   'ã‚ãƒ¼ãƒ¼ï¼ï¼ã¡ã‚‡ã£ã¨ã¾ã£ã¦ãƒ¼ï¼ï¼',
                    'ç©ºé–“ã™ã¹ã¦ã‚’æŠ±ãã—ã‚ãŸããªã£ãŸæ—¥ã€‚',
                    'å¤¢ã‚’èªã‚‹ã ã‘',
                    'æ€ã„å‡ºã€‚',
                    'ãŠã²ã•ã¾ã—ã‹å‹ãŸã‚“',
                    'ã£ã¦ã‹'
                   ]
    
    error_time = ['2023.12.31 16:06',
                  '2023.12.30 19:22',
                  '2023.12.21 21:36',
                  '2023.11.12 23:38',
                  '2023.10.9 21:43',
                  '2023.8.5 21:13',
                  '2023.5.26 17:03',
                  '2023.5.26 15:45',
                  '2022.12.12 23:26',
                   '2022.8.2 09:41',
                   '2021.12.31 19:47',
                   '2021.10.28 23:00'
                  ]
    error_number = 9

    # åˆ¤åˆ¥ã™ã‚‹æ‹¡å¼µå­ã®ãƒªã‚¹ãƒˆ
    extensions_to_check = ['.jpeg', '.jpg', '.png', '.JPG']
    soup = []
    # æŒ‡å®šã—ãŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã«ã‚ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã®æ•°ã‚’å–å¾—
    soup_len = count_files_in_folder("æ—¥å‘å‚ãƒ–ãƒ­ã‚°/html")

    directry = "æ—¥å‘å‚ãƒ–ãƒ­ã‚°"
    html_directry = "html"
    html_dir = os.path.join(directry, html_directry)

    print(soup_len)
    
    for i in range(soup_len):
        soup_dir = os.path.join(html_dir, f"{i}.html")
        print(f"{i}.html")
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰HTMLã‚’èª­ã¿è¾¼ã‚€
        with open(soup_dir, 'r', encoding='utf-8') as file:
            html_content = file.read()
            soup.append(BeautifulSoup(html_content, 'html.parser'))

    # ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹
    with open('hinataNameList.txt', 'r', encoding='utf-8') as file:
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰è¡Œã”ã¨ã«ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã€ãƒªã‚¹ãƒˆã«æ ¼ç´ã™ã‚‹
        name_kanji = [line.strip() for line in file]

    with open('save_dir.json', 'r', encoding='utf-8') as json_file:
        save_dir = json.load(json_file)
    
    for i in range(len(soup)):
        #æ™‚é–“è¨ˆæ¸¬ç”¨
        start_time = ti.time()

        p_article = soup[i].find_all('div',class_="p-blog-article")

        for j in range(len(p_article)):
            article__head = p_article[j].find('div', class_="p-blog-article__head")

            title = article__head.find('div',class_="c-blog-article__title")
            time = article__head.find('div',class_="c-blog-article__date")
            name = article__head.find('div',class_="c-blog-article__name")
            article__text = p_article[j].find('div',class_="c-blog-article__text")

            title = title.text.strip()
            time = time.text.strip()
            name = name.text.strip()
            text = article__text.text.strip()
            text = text.replace("\n","")

            d = {
                'title': title,
                'time' : time,
                'text' : text
            }

            images = article__text.find_all('img')
            split_time = time.split()
            image_folder_name = f'{split_time[0]}_{split_time[1].replace(":", "h")}'

            #ãƒ–ãƒ­ã‚°ã®ãƒšãƒ¼ã‚¸ã‚’0ã‹ã‚‰ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å§‹ã‚ãŸã¨ãã¯ä¸€ç•ªæœ€æ–°ã®ã‚¿ã‚¤ãƒˆãƒ«ã¨æ™‚é–“ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã‚€
            # if initial_Flag and i == 0 and j == 0: 
            #     with open('initial_brog_info.txt','w') as f:
            #         f.write(str(title) + '\n')
            #         f.write(str(time) + '\n')

            if error_time[error_number] == time and error_title[error_number] == title:
                # ç”»åƒã®é‡ãŒå¤šã™ãã‚‹ã¨å…ƒã®HTMLã®æ§‹é€ ã®ãƒã‚°ã®å¯èƒ½æ€§ãŒé«˜ã„ãŸã‚ã€ãƒ–ãƒ­ã‚°ã¯ï¼‘æŠ•ç¨¿ã«ã¤ã30æšä»¥ä¸‹ã ã‚ã†ã¨æ€ã£ãŸã€‚
                if len(images) < 101 :

                    # å–å¾—ã—ã¦ããŸç”»åƒã®URLã«å¯¾ã—ã¦ç©ºã‹ã©ã†ã‹åˆ¤å®š
                    url_images = [image.get('src') for image in images if image.get('src') != ('' or None)]
                    for k in range(len(url_images)):
                        # ã„ãšã‚Œã‹ã®æ‹¡å¼µå­ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ã©ã†ã‹ã‚’åˆ¤å®š
                        contains_extension = any(ext in url_images[k] for ext in extensions_to_check)

                        # å–å¾—ã—ãŸURLãŒç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‹ã©ã†ã‹
                        if contains_extension:
                            image = requests.get(url_images[k])
                            ti.sleep(1)

                            image_path = os.path.join(save_dir[name], image_folder_name)
                            if not os.path.isdir(image_path):
                                os.mkdir(image_path)

                            with open(os.path.join(image_path,f'{k}.jpg'),'wb') as f:
                                f.write(image.content)
                        else:
                            # ã‚¨ãƒ©ãƒ¼ã§ã¯ãªã„æ­£å¸¸ã«æŒ¯ã‚Šåˆ†ã‘ã‚‰ã‚Œã¦ã„ã‚‹ã—ã€ã—ã£ã‹ã‚Šã¨ã“ã‚Œã‚‰ã‚’é™¤å»ã—ã¦ç”»åƒãŒä¿å­˜ã§ãã¦ã„ã‚‹ã€‚
                            # image_error(d,"æŒ‡å®šã—ãŸæ‹¡å¼µå­ä»¥å¤–ã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã™",errorNumber,url_images)
                            # errorNumber += 1
                            print("æŒ‡å®šã—ãŸæ‹¡å¼µå­ä»¥å¤–ã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–ã‚Šé™¤ãã¾ã—ãŸ")
                    print('\t'+ f'{name}ã«ãŠã„ã¦{len(images)}æšã®å†™çœŸã‚’ä¿å­˜ã—ã¾ã—ãŸ')
                # else :
                    # image_error(d,"ç”»åƒãŒ30æšä»¥ä¸Šã‚ã‚Šã¾ã™",errorNumber)
                error_number += 1
                print("error_number",error_number)
                
        print(i , ' ãƒšãƒ¼ã‚¸ç›®ãŒçµ‚ã‚ã‚Šã¾ã—ãŸ')
        #1ã¤ã®ãƒšãƒ¼ã‚¸ãŒã©ã®ãã‚‰ã„ã§çµ‚ã‚ã‚‹ã‹
        end_time = ti.time()
        excution_time = end_time - start_time
        print(f"{excution_time/60:.2f} åˆ†ã‹ã‹ã‚Šã¾ã—ãŸã€‚")

load()